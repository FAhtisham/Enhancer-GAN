{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>  Enhancer Pixel Sequence  Deep Convolutional Generative Adversarial Network </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[1],'GPU')\n",
    "\n",
    "#tf.config.experimental.set_memory_growth(gpus[2],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for device in gpus:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tqdm \n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense, LeakyReLU, Conv1D, Conv2D, Conv2DTranspose, Flatten\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the variables for the ease of use in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_dir = './images/'\n",
    "images_count = 32693\n",
    "width = 28\n",
    "height = 28\n",
    "images = []\n",
    "x1 =  0\n",
    "y1 = 0\n",
    "x2 = 152\n",
    "y2 = 104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(pic_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pic_file in tqdm.tqdm(os.listdir(pic_dir)[:images_count]):\n",
    "    # Saving the aspect ratio and properties of images using thumbnail and antialias\n",
    "    pic = Image.open(pic_dir + pic_file)\n",
    "    images.append(img_to_array(pic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the images into num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting images into numpy and normalizing the vals\n",
    "images = ((np.array(images)-127.5)/ 127.5)\n",
    "print(\"Images Normalized...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming the size\n",
    "images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(x_train): \n",
    "    batch_size = 30\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000) \n",
    "    # Combines consecutive elements of this dataset into batches. \n",
    "    dataset = dataset.batch(batch_size, drop_remainder = True).prefetch(1) \n",
    "    # Creates a Dataset that prefetches elements from this dataset \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_batch(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Generator side of the DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector = 100\n",
    "channel = 1\n",
    "def generator_model():\n",
    "    # Flattened and noise vector\n",
    "    generator_input = keras.Input(shape = (latent_vector,))\n",
    "    \n",
    "    # Starting from a Dense layer\n",
    "    x = Dense(100 * 28 * 28)(generator_input)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    # Reshaping to organize \n",
    "    x = Reshape((28, 28, 100))(x)\n",
    "    \n",
    "    # Applying convlution operation to get some initial features\n",
    "    # Applying 155 filters with a kernel size of 5\n",
    "    # We dont add padding to make it of equivalent size as input\n",
    "    x = Conv2D(filters = 256, kernel_size = 6, strides=4, padding=\"same\")(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    \n",
    "    # Applying the transpose operation so that when the conv is applied we get matrix of higher dimensions i-e. https://www.machinecurve.com/index.php/2019/09/29/understanding-transposed-convolutions/\n",
    "    # https://distill.pub/2016/deconv-checkerboard/\n",
    "    x = Conv2DTranspose(filters = 256, kernel_size = 2, strides=2, padding = \"same\")(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    \n",
    "    # Conv2DTrans num 2\n",
    "    x = Conv2DTranspose(filters = 256, kernel_size = 4, strides=2, padding = \"same\")(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2D(channel, kernel_size = 7, activation='tanh', padding='same')(x)\n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    '''  \n",
    "       # Conv2DTrans num 3\n",
    "    x = Conv2DTranspose(filters = 256, kernel_size = 4, strides=2, padding = \"same\")(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2D(filters = 512, kernel_size = 4, padding=\"same\" )(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2D(filters = 512, kernel_size = 6, padding=\"same\" )(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    generator = Model(generator_input, x)\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Discriminator side of the DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    \n",
    "    # Defining the shape of the input that is to be given as input\n",
    "    discriminator_input = keras.Input(shape = (28, 28, 1))\n",
    "    \n",
    "    # Defining the convolution layer in a way so that the size is reduced to its half\n",
    "    x = Conv2D(filters = 228, kernel_size = 2, strides = 2)(discriminator_input)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    # conv layer 2\n",
    "    x = Conv2D(filters=104, kernel_size=2, strides=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(rate=0.3)(x)\n",
    "    \n",
    "    # conv layer 3\n",
    "    #x = Conv2D(filters=52, kernel_size=2, strides=2)(x)\n",
    "    #x = LeakyReLU()(x)\n",
    "    \n",
    "    # conv layer 4\n",
    "    # x = Conv2D(filters=26, kernel_size=2, strides=2)(x)\n",
    "    #x = LeakyReLU()(x)\n",
    "    \n",
    "    # Flattening the matrixes\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Performing the regularization to minimize overfitting\n",
    "    x = Dropout(rate=0.3)(x)\n",
    "    \n",
    "    # Defining the output from the discriminator which is always the probability\n",
    "    x = Dense(units=1, activation='sigmoid')(x)\n",
    "    \n",
    "    # From a tensor to a complete model\n",
    "    discriminator = Model(discriminator_input , x )\n",
    "    '''\n",
    "    # Defining the optimizer for the Discriminator\n",
    "    optimizer = tf.keras.optimizers.RMSprop(\n",
    "        rho=0.9,\n",
    "        momentum=0.0,\n",
    "        epsilon=1e-07,\n",
    "        centered=False,\n",
    "        learning_rate=0.001,\n",
    "        clipvalue=1.0\n",
    "    )\n",
    "    \n",
    "    # Compiling the model\n",
    "    discriminator.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss = keras.losses.binary_crossentropy\n",
    "    )\n",
    "    '''\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator=create_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the image using the untrained Generator\n",
    "\n",
    "**Using the (as yet untrained) generator to create an image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating random vector of size 100 from Normal Distribution\n",
    "noise = tf.random.normal([1,100])\n",
    "print(\"tensor created with the random values of size 100 ...\")\n",
    "\n",
    "# No training has been specified\n",
    "generated_image = generator(noise, training=False)\n",
    "plt.figure(1, figsize=(10, 10))\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using untrained discriminator to classify the generated images as real or fake\n",
    "\n",
    "**The model will be trained to output positive values for real images, and negative values for fake images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling and combining phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile discriminator using binary cross entropy loss and adam optimizer \n",
    "discriminator.compile(loss =\"binary_crossentropy\", optimizer =\"adam\") \n",
    "# make  discriminator no-trainable as of  now \n",
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both generator and discriminator \n",
    "gan = keras.models.Sequential([generator, discriminator])\n",
    "# compile generator using binary cross entropy loss and adam optimizer\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "# We have already defined latent_vector ppreviously\n",
    "batch_size = 30\n",
    "# Creating the random vector from noise \n",
    "total_vec_seed = tf.random.normal(shape=[batch_size, latent_vector])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vec_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dcgan(gan, images, batch_size, num_features, epochs=3):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        print()\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, epochs))\n",
    "        for X_batch in images:\n",
    "            # Create a random noise of size batch * 100\n",
    "            noise = tf.random.normal(shape=[batch_size, num_features])\n",
    "            generated_images = generator(noise)\n",
    "           \n",
    "            # Combining the real and fake images to train the discriminator\n",
    "            fake_and_real = tf.concat((generated_images, X_batch), axis=0)\n",
    "            \n",
    "            # Providing batch of real and fake images to the discrimnator\n",
    "            # training the discriminator using it\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable=True\n",
    "            discriminator.train_on_batch(fake_and_real, y1)\n",
    "            # Training the GAN\n",
    "            # Providing the generated images and fooling the discriminator with fake labels of 1\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable=False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "        \n",
    "            # Generate and save images\n",
    "            #generate_and_save_images(generator, epoch+1, noise)\n",
    "            \n",
    "        print(discriminator.evaluate(fake_and_real, y1))\n",
    "        \n",
    "        \n",
    "        generate_and_save_images(generator, epoch, noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining and saving Image Generation Via Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_to =list()\n",
    "preds_for=list()\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training = False)\n",
    "    preds_to.append(predictions)\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        preds_to_show = predictions[i, :, :] * 127.5 + 127.5\n",
    "        \n",
    "        #preds_to_show = np.squeeze(preds_to_show)\n",
    "        plt.imshow(preds_to_show, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "    \n",
    "    plt.savefig('image_epoch_{:04d}.png'.format(epoch))\n",
    "    #print(\"Before norm\",preds_to)\n",
    "    #print(\"After norm\", preds_for)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dcgan(gan, dataset, batch_size, latent_vector, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan_moin",
   "language": "python",
   "name": "gan_moin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
